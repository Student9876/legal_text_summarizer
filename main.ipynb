{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries\n",
    "Import all required libraries for text processing, including NLTK, spaCy, or other NLP libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Shouv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Shouv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Shouv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Shouv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Download NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Preprocessing Functions\n",
    "Create functions to clean and preprocess text, such as tokenization, stopword removal, and sentence segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Preprocessing Functions\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "import string\n",
    "from rouge import Rouge\n",
    "import os\n",
    "\n",
    "# Function to clean and preprocess text\n",
    "def clean_text(text):\n",
    "    \"\"\"Clean and preprocess text\"\"\"\n",
    "    if isinstance(text, str):\n",
    "        # Convert to lowercase\n",
    "        text = text.lower()\n",
    "        # Remove special characters and digits\n",
    "        text = re.sub(r'\\W', ' ', text)\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        text = text.strip()\n",
    "        return text\n",
    "    return \"\"\n",
    "\n",
    "def preprocess_text(text):\n",
    "    if not isinstance(text, str) or not text:\n",
    "        return []\n",
    "    cleaned = clean_text(text)\n",
    "    words = word_tokenize(cleaned)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    filtered_words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
    "    return filtered_words  # Return words instead of reconstructed sentences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extractive Summary Generation\n",
    "Summarization function using extractive summarization with TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarization function using extractive summarization with TF-IDF\n",
    "def summarize_text(text, max_sentences=5):\n",
    "    if not isinstance(text, str) or not text:\n",
    "        return \"\"\n",
    "        \n",
    "    # Get original sentences\n",
    "    original_sentences = sent_tokenize(text)\n",
    "    if len(original_sentences) <= max_sentences:\n",
    "        return text\n",
    "        \n",
    "    # Preprocess sentences (retain non-empty sentences)\n",
    "    preprocessed_sentences = []\n",
    "    valid_indices = []  # Track indices of non-empty preprocessed sentences\n",
    "    for idx, sentence in enumerate(original_sentences):\n",
    "        processed = preprocess_text(sentence)\n",
    "        if processed:  # Skip empty sentences\n",
    "            preprocessed_sentences.append(' '.join(processed))\n",
    "            valid_indices.append(idx)\n",
    "    \n",
    "    if len(preprocessed_sentences) <= max_sentences:\n",
    "        return text\n",
    "        \n",
    "    # TF-IDF and scoring\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    try:\n",
    "        tfidf_matrix = vectorizer.fit_transform(preprocessed_sentences)\n",
    "    except ValueError:\n",
    "        return text  # Handle empty vocabulary\n",
    "        \n",
    "    similarity_matrix = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "    sentence_scores = np.sum(similarity_matrix, axis=1)\n",
    "    \n",
    "    # Select top sentences from valid_indices\n",
    "    top_indices = np.argsort(sentence_scores)[-max_sentences:]\n",
    "    selected_original_indices = [valid_indices[i] for i in top_indices]\n",
    "    selected_original_indices = sorted(selected_original_indices)\n",
    "    \n",
    "    summary = ' '.join([original_sentences[i] for i in selected_original_indices])\n",
    "    return summary\n",
    "    \n",
    "# Evaluation function\n",
    "def evaluate_summary(reference_summary, generated_summary):\n",
    "    \"\"\"Evaluate summary using ROUGE scores\"\"\"\n",
    "    rouge = Rouge()\n",
    "    \n",
    "    if not reference_summary or not generated_summary:\n",
    "        return {\"rouge-1\": {\"f\": 0.0}, \"rouge-2\": {\"f\": 0.0}, \"rouge-l\": {\"f\": 0.0}}\n",
    "        \n",
    "    try:\n",
    "        scores = rouge.get_scores(generated_summary, reference_summary)[0]\n",
    "        return scores\n",
    "    except Exception:\n",
    "        return {\"rouge-1\": {\"f\": 0.0}, \"rouge-2\": {\"f\": 0.0}, \"rouge-l\": {\"f\": 0.0}}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully with 24985 rows\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    legal_data = pd.read_csv('legal_text_classification.csv')\n",
    "    print(f\"Dataset loaded successfully with {legal_data.shape[0]} rows\")\n",
    "    # Force 'case_text' as the text column\n",
    "    if 'case_text' not in legal_data.columns:\n",
    "        raise ValueError(\"Column 'case_text' not found in dataset\")\n",
    "    text_column = 'case_text'\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    exit()\n",
    "    \n",
    "# Check if the dataset has a 'case_text' column\n",
    "if 'case_text' not in legal_data.columns:\n",
    "    print(\"Error: 'case_text' column not found in the dataset\")\n",
    "    # Handle error or exit\n",
    "else:\n",
    "    text_column = 'case_text'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply summarization to the legal texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarizing legal texts...\n"
     ]
    }
   ],
   "source": [
    "print(\"Summarizing legal texts...\")\n",
    "legal_data['summary'] = legal_data[text_column].apply(lambda x: summarize_text(str(x), max_sentences=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "legal_data['original_length'] = legal_data[text_column].apply(lambda x: len(str(x)))\n",
    "legal_data['summary_length'] = legal_data['summary'].apply(len)\n",
    "legal_data['compression_ratio'] = legal_data['summary_length'] / legal_data['original_length']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarization complete!\n",
      "Average compression ratio: 0.56\n"
     ]
    }
   ],
   "source": [
    "print(\"Summarization complete!\")\n",
    "print(f\"Average compression ratio: {legal_data['compression_ratio'].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the results to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to legal_text_summaries.csv\n"
     ]
    }
   ],
   "source": [
    "output_file = 'legal_text_summaries.csv'\n",
    "legal_data.to_csv(output_file, index=False)\n",
    "print(f\"Results saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Sample Summaries ---\n",
      "\n",
      "Original text (excerpt): The weight the Tribunal accords the material before it is ultimately a factual matter for the Tribunal ( Lee v Minister for Immigration and Multicultural and Indigenous Affairs [2005] FCA 464 ; Minist...\n",
      "Summary: It is not, as the first appellant submitted, an error of law, or a jurisdictional error, for the Tribunal to base a decision on 'country information' that is not true. The very function of the Tribunal was to assess the appellants' claims, both as to their inherent credibility and as to their consistency with other information known to the Tribunal about circumstances in the appellants' country of origin. It is clear from the reasons for decision that the Tribunal did rely on 'country information' in making its assessment of the future, and that the conclusion that it reached was open to the Tribunal on the basis of the material it used.\n",
      "Compression ratio: 0.20\n",
      "\n",
      "Original text (excerpt): Aporo had a reasonable opportunity to ascertain and respond to the determinative issues that arose ( Commissioner for Australian Capital Territory Revenue v Alphaone Pty Ltd [1994] FCA 1074 ; (1994) 4...\n",
      "Summary: The Tribunal did not make findings of fact as to which there was no evidence advanced by Mr Aporo or no submissions made. Mr Aporo says that the Tribunal's conclusions were arbitrary and based on speculation. Mr Aporo says that the Tribunal's conclusions were based upon its own observations, expertise or experience.\n",
      "Compression ratio: 0.17\n",
      "\n",
      "Original text (excerpt): The scheme is a scheme for the reconstruction of the company. It passes the test set out by Buckley J in Re South African Supply and Cold Storage (1904) 2 Ch 268 at 286. The undertaking is being trans...\n",
      "Summary: 14 I have been provided with a helpful written outline of pSivida Ltd's submissions. In accordance with the practice usually followed, I will mark the outline of submissions as MFI 1, but will not make any further reference to them in these reasons. 15 I am satisfied that I should make orders in accordance with the short minutes of order which I have now signed and dated and placed with the Court papers.\n",
      "Compression ratio: 0.33\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Sample Summaries ---\")\n",
    "sample_indices = np.random.choice(legal_data.index, min(3, len(legal_data)), replace=False)\n",
    "for idx in sample_indices:\n",
    "    print(f\"\\nOriginal text (excerpt): {legal_data.loc[idx, text_column][:200]}...\")\n",
    "    print(f\"Summary: {legal_data.loc[idx, 'summary']}\")\n",
    "    print(f\"Compression ratio: {legal_data.loc[idx, 'compression_ratio']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
